# **Kenyan Sign Language Interpreter**

**Project Overview**

The **Kenyan Sign Language Interpreter** is a web-based application designed to interpret Kenyan Sign Language (KSL) in real time using Artificial Intelligence. The system leverages **TensorFlow** and **OpenCV** to capture and process sign language gestures and translates them into understandable text. The goal is to create an accessible and user-friendly interface that bridges the communication gap for the deaf community in Kenya.

**Key Features**

•	**Real-time sign language interpretation** using webcam input.

•	**Convolutional Neural Network (CNN) model** trained on a dataset of sign language images.

•	**Web-based interface** built with **Node.js** and **Express.js** for ease of use.

**Technologies Used**

•	**Programming Languages:** Python, JavaScript

•	**Frameworks/Libraries:**

•	TensorFlow (for AI and machine learning)

•	OpenCV (for image capture and preprocessing)

•	Node.js, Express.js (for web interface development)

•	**Tools:** Git for version control, any preferred IDE (e.g., PyCharm, VS Code)

**Installation & Setup**

1.	**Clone the repository**:

git clone https:*//github.com/faith-terer/kenyan-sign-language-interpreter.git*

2.	**Install required dependencies**:

pip install -r requirements.txt

3.	**Run the backend server**:

node app.js

4.	**Access the web application** in your browser at:

http:*//localhost:3000*

**Usage Instructions**

1.	Connect your webcam.

2.	Open the web application and allow access to your webcam.

3.	The system will capture and process your sign language gestures in real-time, translating them to text.

**Future Enhancements**

•	**Improve gesture accuracy:** Further training of the model on larger datasets.

•	**Add voice output:** Implement text-to-speech for audio translation of gestures.

•	**Mobile version:** Develop a mobile-friendly version for ease of use on smartphones.